{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File to work on the training process for self supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import extract_colmap as c\n",
    "import numpy as np\n",
    "import torch \n",
    "import os\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "#ghost_city_bin_path='raw/test/bin_files/ghost_city_bins/images.bin'\n",
    "#medium_structure_bin_path='raw/test/bin_files/medium_structure_bins/images.bin'\n",
    "\n",
    "### IMPORTANT PATHS\n",
    "ghost_city_bin_path='/home/server/Ines/models/raw/test/bin_files/ghost_city_bins/images.bin'\n",
    "medium_structure_bin_path='/home/server/Ines/models/raw/test/bin_files/medium_structure_bins/images.bin'\n",
    "thermitiere_bin_path='/home/server/Ines/models/raw/train/bin_files/thermitiere_bins/images.bin'\n",
    "old_cliff_bin_path='/home/server/Ines/models/raw/train/bin_files/old_rainbow_cliff_bins/images.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the quaternion to the rotation matrix:\n",
    "\n",
    "def quaternion_rotation_matrix(Q):\n",
    "    \"\"\"\n",
    "    Coverts a quaternion into a full three-dimensional rotation matrix.\n",
    " \n",
    "    Input\n",
    "    :param Q: A 4 element array representing the quaternion (q0,q1,q2,q3) \n",
    " \n",
    "    Output\n",
    "    :return: A 3x3 element matrix representing the full 3D rotation matrix. \n",
    "             This rotation matrix converts a point in the local reference \n",
    "             frame to a point in the global reference frame.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check the quaternion size:\n",
    "    if len(Q)!=4:\n",
    "        return 'SizeError: A quaternion contains 4 values'\n",
    "    \n",
    "    # Extract the values from Q\n",
    "    q0 = Q[0]\n",
    "    q1 = Q[1]\n",
    "    q2 = Q[2]\n",
    "    q3 = Q[3]\n",
    "     \n",
    "    # First row of the rotation matrix\n",
    "    r00 = 2 * (q0 * q0 + q1 * q1) - 1\n",
    "    r01 = 2 * (q1 * q2 - q0 * q3)\n",
    "    r02 = 2 * (q1 * q3 + q0 * q2)\n",
    "     \n",
    "    # Second row of the rotation matrix\n",
    "    r10 = 2 * (q1 * q2 + q0 * q3)\n",
    "    r11 = 2 * (q0 * q0 + q2 * q2) - 1\n",
    "    r12 = 2 * (q2 * q3 - q0 * q1)\n",
    "     \n",
    "    # Third row of the rotation matrix\n",
    "    r20 = 2 * (q1 * q3 - q0 * q2)\n",
    "    r21 = 2 * (q2 * q3 + q0 * q1)\n",
    "    r22 = 2 * (q0 * q0 + q3 * q3) - 1\n",
    "     \n",
    "    # 3x3 rotation matrix\n",
    "    rot_matrix = np.array([[r00, r01, r02],\n",
    "                           [r10, r11, r12],\n",
    "                           [r20, r21, r22]])\n",
    "                            \n",
    "    return rot_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25.82  3.   46.8 ]\n",
      " [45.   39.82 27.4 ]\n",
      " [13.2  52.6  57.82]]\n"
     ]
    }
   ],
   "source": [
    "print(quaternion_rotation_matrix((2.1,3,4,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form the reference change matrix\n",
    "\n",
    "def get_T_matrix(qvec, tvec):\n",
    "    if len(qvec)!=4:\n",
    "        return 'SizeError: A quaternion contains 4 values'\n",
    "\n",
    "    if len(tvec)!=3:\n",
    "        return 'SizeError: A translation contains 3 values'\n",
    "    \n",
    "    # Extract the values from Q\n",
    "    q0 = qvec[0]\n",
    "    q1 = qvec[1]\n",
    "    q2 = qvec[2]\n",
    "    q3 = qvec[3]\n",
    "     \n",
    "    # First row of the rotation matrix\n",
    "    r00 = 2 * (q0 * q0 + q1 * q1) - 1\n",
    "    r01 = 2 * (q1 * q2 - q0 * q3)\n",
    "    r02 = 2 * (q1 * q3 + q0 * q2)\n",
    "     \n",
    "    # Second row of the rotation matrix\n",
    "    r10 = 2 * (q1 * q2 + q0 * q3)\n",
    "    r11 = 2 * (q0 * q0 + q2 * q2) - 1\n",
    "    r12 = 2 * (q2 * q3 - q0 * q1)\n",
    "     \n",
    "    # Third row of the rotation matrix\n",
    "    r20 = 2 * (q1 * q3 - q0 * q2)\n",
    "    r21 = 2 * (q2 * q3 + q0 * q1)\n",
    "    r22 = 2 * (q0 * q0 + q3 * q3) - 1\n",
    "     \n",
    "    # 3x3 rotation matrix\n",
    "    rot_matrix = np.array([[r00, r01, r02],\n",
    "                           [r10, r11, r12],\n",
    "                           [r20, r21, r22]])\n",
    "\n",
    "    # Full T_world-->cam matrix\n",
    "    T=np.array([[r00, r01, r02, tvec[0]],\n",
    "                [r10, r11, r12, tvec[1]],\n",
    "                [r20, r21, r22, tvec[2]],\n",
    "                ])\n",
    "    return T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  4 22  5]\n",
      " [20 19 20  6]\n",
      " [10 28 33  7]]\n"
     ]
    }
   ],
   "source": [
    "q_test=(1,2,3,4)\n",
    "t_test=(5,6,7)\n",
    "print(get_T_matrix(q_test, t_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reprojection error between two images \n",
    "\n",
    "def get_reproj_error(I1, I2, T1, T2, K, d1):\n",
    "    \"\"\"\n",
    "    Inputs: A sequential set of 2 images (I1, I2)\n",
    "            Their associated pose camera (from world to the camera pose) (T1, T2) (4*4 matrix)\n",
    "            The camera calibration matrix K\n",
    "            The predicted depth map d1\n",
    "    Output: The reprojection error between the 2 images  R_1-->2\n",
    "    \"\"\"\n",
    "    error=0\n",
    "    H,W=np.shape(I1)\n",
    "\n",
    "    # Changing references\n",
    "    T2_inv=np.linalg.pinv(T2)\n",
    "    K_inv=np.linalg.inv(K)    \n",
    "  \n",
    "\n",
    "     # Checking shapes \n",
    "\n",
    "    print('T2 shape', np.shape(T2))\n",
    "    print('T1 shape', np.shape(T1))\n",
    "    print('T2_inv shape', np.shape(T2_inv))\n",
    "    print('K_inv shape', np.shape(K_inv))\n",
    "\n",
    "    # Bruh\n",
    "    G1= np.transpose(T1)@ K_inv\n",
    "    G1= np.transpose(T2_inv) @ G1\n",
    "    G1= K @ G1\n",
    "\n",
    "    # R_1-->2\n",
    "    for u in range(H):\n",
    "        for v in range(W):\n",
    "                p1=np.array([u, v, 1])\n",
    "                p2=np.array(G1 @ (d1[u,v]*p1))\n",
    "                delta=p1-p2\n",
    "                # Euclidean distance\n",
    "                error+=np.sqrt(delta[0]**2+delta[1]**2)\n",
    "                \n",
    "    return error\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T2 shape (3, 4)\n",
      "T1 shape (3, 4)\n",
      "T2_inv shape (4, 3)\n",
      "K_inv shape (3, 3)\n",
      "T2 shape (3, 4)\n",
      "T1 shape (3, 4)\n",
      "T2_inv shape (4, 3)\n",
      "K_inv shape (3, 3)\n",
      "627.9614489861225\n",
      "1029.6451936835952\n"
     ]
    }
   ],
   "source": [
    "## DUMMY VALUES \n",
    "\n",
    "I1=np.ones((5,5))\n",
    "I2=3*np.ones((5,5))\n",
    "K=np.array([[1, 0, 0.3],\n",
    "            [0, 1, 0.2],\n",
    "            [0, 0,   1],\n",
    "            ])\n",
    "\n",
    "T1= np.array([[ 9, 4, 22,  5],\n",
    " [20, 19, 20,  6],\n",
    " [10, 28, 33,  7]])\n",
    "\n",
    "T2= np.array([[ 9, 4, 12,  5],\n",
    " [20, 3, 20,  6],\n",
    " [10, 28, 6,  7]])\n",
    "\n",
    "d1=np.ones((5,5))\n",
    "\n",
    "d2=4*np.ones((5,5))\n",
    "\n",
    "err_12=get_reproj_error(I1, I2, T1, T2, K, d1)\n",
    "err_21=get_reproj_error(I2, I1, T1, T2, K, d2)\n",
    "print(err_12)\n",
    "print(err_21)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n"
     ]
    }
   ],
   "source": [
    "# How it is going to look like in the trainig process. \n",
    "train_loader=None\n",
    "\n",
    "for image, T in train_loader:\n",
    "    # Reminder= image, T are batches of batch_size elements\n",
    "\n",
    "    #Moving to GPU \n",
    "    image.to(device)\n",
    "    T.to(device)\n",
    "\n",
    "    #Right type\n",
    "    image_batch=image.type(torch.cuda.FloatTensor)\n",
    "    # T = np.array\n",
    "\n",
    "    # Going through the network\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('monocular')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45f2bed9a0e297c8321bc81029f3c022b6b1f82f3e99e7b1fe109da730cb5db3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
