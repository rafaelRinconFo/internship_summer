{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d86f4b6-f13a-4da0-904c-dcf9a6710307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision \n",
    "import networks\n",
    "\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self, network, network_name, device, train_loader, test_loader, optimizer, loss_fuction, num_epochs, save_model_path, save_optim_path):\n",
    "        \"\"\"Taking in input all the parameters necessary for training\"\"\"\n",
    "        self.network=network\n",
    "        self.network_name=network_name\n",
    "        self.device=device\n",
    "        self.train_loader=train_loader\n",
    "        self.test_loader=test_loader\n",
    "        self.optimizer=optimizer\n",
    "        self.num_epochs=num_epochs\n",
    "        self.loss_function=loss_function\n",
    "        self.save_model_path=save_model_path\n",
    "        self.save_optim_path=save_optim_path\n",
    "\n",
    "        \n",
    "        \n",
    "    def validation_epoch(self):\n",
    "            self.network.eval()  # evaluation mode, equivalent to \"network.train(False)\"\"\n",
    "            val_loss = 0\n",
    "            rmse_epoch=[]\n",
    "            rmse_log_epoch=[]\n",
    "            abs_rel_epoch=[]\n",
    "            sq_rel_epoch=[]\n",
    "            a1_epoch=[]\n",
    "            a2_epoch=[]\n",
    "            a3_epoch=[]\n",
    "\n",
    "\n",
    "            with torch.no_grad(): # No need to track the gradients\n",
    "                for image, depth_map in self.test_dataloader:\n",
    "                    #Moving to GPU\n",
    "                    image.to(self.device)\n",
    "                    d = depth_map.to(self.device)\n",
    "                    #Applying the necessary transforms\n",
    "\n",
    "                    image = image.type(torch.cuda.FloatTensor)\n",
    "                    d=d.type(torch.cuda.FloatTensor)\n",
    "\n",
    "                    #Going through the network\n",
    "                    if self.network_name=='midas':\n",
    "                        inv_d_hat = self.network(image.squeeze(1))\n",
    "                    else:\n",
    "                        inv_d_hat = self.network(image.squeeze())\n",
    "                    \n",
    "                    inv_d=1/d\n",
    "                    inv_d[inv_d==np.inf]=0\n",
    "                    \n",
    "                    #Computing the loss, storing it\n",
    "                    if self.network_name=='midas':\n",
    "                        loss=loss_function(inv_d_hat.squeeze(),  inv_d, mask).float()\n",
    "                    else:\n",
    "                        loss=loss_function(inv_d_gat, inv_d, mask).float()\n",
    "                    \n",
    "                    val_loss += loss.item()\n",
    "                    \n",
    "\n",
    "    def train_epoch(self):\n",
    "        \"Trains the model for one epoch\"\n",
    "        self.network.train()\n",
    "        total_loss_epoch=0\n",
    "\n",
    "\n",
    "        # Iterate the dataloader (We do not need the label value which is 0 here, the depth maps are the labels)\n",
    "        iter = 0\n",
    "        for image, depth_map in self.train_loader:   \n",
    "            #Moving to GPU\n",
    "            image.to(self.device)\n",
    "            d = depth_map.to(self.device)\n",
    "\n",
    "            #Right size and type\n",
    "            image=image.squeeze()\n",
    "            image = image.type(torch.cuda.FloatTensor)\n",
    "            d=d.type(torch.cuda.FloatTensor)\n",
    "\n",
    "\n",
    "            #Going through the network\n",
    "            inv_d_hat = network(image)\n",
    "\n",
    "                \n",
    "\n",
    "            #Computing the loss, storing it\n",
    "            mask=d>0.0\n",
    "\n",
    "            #Not taking into account the zones where there is no data available (mask)\n",
    "\n",
    "            #From depth map to the inverse depth map\n",
    "            inv_d=1/d\n",
    "            inv_d[inv_d==np.inf]=0\n",
    "            if self.network_name=='midas':\n",
    "                loss=self.loss_function(inv_d_hat.squeeze(),  inv_d, mask).float()\n",
    "            else:\n",
    "                loss=self.loss_function(inv_d_hat.squeeze(),  inv_d, mask).float()\n",
    "\n",
    "\n",
    "            #Store batch loss\n",
    "            total_loss_epoch += loss.item()\n",
    "\n",
    "            # Backward pass\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()  \n",
    "            self.optimizer.step() \n",
    "\n",
    "        return total_loss_epoch\n",
    "    \n",
    "    \n",
    "    \n",
    "    def full_training_process(self, print_metrics=True, lr_decay=False):\n",
    "        train_losses = []\n",
    "        val_loss, abs_rel, sq_rel, rmse, rmse_log, a1, a2, a3=self.validation_epoch(self.network, self.device, self.loss_function, self.test_loader)\n",
    "        val_losses = [val_loss] #first evaluation before training\n",
    "        weight_decay=1e-4\n",
    "        lr=1e-4\n",
    "        for epoch in range(self.num_epochs):\n",
    "            if lr_decay:\n",
    "                if epoch>50:\n",
    "                    if epoch%10==0:\n",
    "                        lr/=5\n",
    "                        optim=torch.optim.Adam(self.network.parameters(), lr=lr, weight_decay=weight_decay, eps=1e-20)\n",
    "\n",
    "            #Optimising the model \n",
    "            train_loss_epoch= self.train_epoch(self.network, self.device, self.train_loader, self.optim, self.loss_function)\n",
    "            \n",
    "\n",
    "            #Assessing the model performance during training\n",
    "            val_loss_epoch, abs_rel_epoch, sq_rel_epoch, rmse_epoch, rmse_log_epoch, a1_epoch, a2_epoch, a3_epoch  = self.validation_epoch(self.network, self.device, self.loss_function, self.test_loader)\n",
    "            #all those values are floats\n",
    "            \n",
    "\n",
    "            #Storing \n",
    "            train_losses.append(train_loss_epoch)\n",
    "            val_losses.append(val_loss_epoch)\n",
    "\n",
    "            abs_rel.append(abs_rel_epoch)\n",
    "            sq_rel.append(sq_rel_epoch)\n",
    "            rmse.append(rmse_epoch)\n",
    "            rmse_log.append(rmse_epoch)\n",
    "            a1.append(a1_epoch)\n",
    "            a2.append(a2_epoch)\n",
    "            a3.append(a3_epoch)\n",
    "\n",
    "\n",
    "            print(f'\\n EPOCH {epoch + 1}/{num_epochs} \\t train loss {train_loss_epoch:.4f} \\t val loss {val_loss_epoch:.4f} ')\n",
    "            if print_metrics:\n",
    "                print(f'\\n RMSE {rmse[-1]:.4f} \\t RMSLE {rmse_log[-1]:.4f} \\t abs rel {abs_rel[-1]:.4f} \\t sq rel {sq_rel[-1]:.4f}')\n",
    "\n",
    "            # Storing the network weights if the RMSE decreazes (otherwise continue training is not interesting)\n",
    "            if rmse[-1]<lowest_RMSE_value:\n",
    "                lowest_RMSE_value=rmse[-1]\n",
    "                torch.save(self.network.state_dict(), self.model_save_path )\n",
    "                torch.save(self.optim.state_dict(), self.optim_save_path)\n",
    "\n",
    "\n",
    "        return train_losses, val_losses, rmse, rmse_log, abs_rel, sq_rel, a1, a2, a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ed9d675-cf29-4d3e-a1a9-3991d84064be",
   "metadata": {},
   "outputs": [],
   "source": [
    "network, network_name, device, train_loader, test_loader, optimizer, loss_function, num_epochs, save_model_path, save_optim_path= None, None, None, None, None, None, None, None, None, None\n",
    "test_trainer=Trainer(network, network_name, device, train_loader, test_loader, optimizer, loss_function, num_epochs, save_model_path, save_optim_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57283c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_epoch(self):\n",
    "\t\tself.network.eval()  # evaluation mode, equivalent to \"network.train(False)\"\"\n",
    "\t\tval_loss = 0\n",
    "\t\trmse_epoch=[]\n",
    "\t\trmse_log_epoch=[]\n",
    "\t\tabs_rel_epoch=[]\n",
    "\t\tsq_rel_epoch=[]\n",
    "\t\ta1_epoch=[]\n",
    "\t\ta2_epoch=[]\n",
    "\t\ta3_epoch=[]\n",
    "\n",
    "\n",
    "\t\twith torch.no_grad(): # No need to track the gradients\n",
    "\t\t\tfor image, depth_map in self.test_dataloader:\n",
    "\t\t\t\t#Moving to GPU\n",
    "\t\t\t\timage.to(self.device)\n",
    "\t\t\t\td = depth_map.to(self.device)\n",
    "\t\t\t\t#Applying the necessary transforms\n",
    "\t\t\t\t#image=image.squeeze()\n",
    "\t\t\t\timage = image.type(torch.cuda.FloatTensor)\n",
    "\t\t\t\td=d.type(torch.cuda.FloatTensor)\n",
    "\n",
    "\t\t\t\t#Going through the network\n",
    "\t\t\t\tinv_d_hat = self.network(image.squeeze(1))\n",
    "\t\t\t\tinv_d=1/d\n",
    "\t\t\t\tinv_d[inv_d==np.inf]=0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t\t\t\t#Computing the loss, storing it\n",
    "\t\t\t\tmask=d>0.0\n",
    "\t\t\t\tloss=self.loss_function(inv_d_hat.squeeze(),  inv_d, mask).float()\n",
    "\n",
    "\t\t\t\tval_loss += loss.item()\n",
    "\n",
    "\t\t\t\t#Store values for metrics : they have to be computed on depth maps.\n",
    "\t\t\t\td_hat=1/inv_d_hat\n",
    "\n",
    "\t\t\t\td_hat[d_hat==np.inf]=0 \n",
    "\t\t\t\tabs_rel, sq_rel, rmse, rmse_log, a1, a2, a3 = compute_errors_2(d.detach().cpu(), d_hat.detach().cpu())\n",
    "\n",
    "\n",
    "\t\t\t\tabs_rel_epoch.extend(abs_rel)\n",
    "\t\t\t\tsq_rel_epoch.extend(sq_rel)\n",
    "\t\t\t\trmse_epoch.extend(rmse)\n",
    "\t\t\t\trmse_log_epoch.extend(rmse_log)\n",
    "\t\t\t\ta1_epoch.extend(a1)\n",
    "\t\t\t\ta2_epoch.extend(a2)\n",
    "\t\t\t\ta3_epoch.extend(a3)\n",
    "\n",
    "\t\treturn val_loss, np.array(abs_rel_epoch).mean(), np.array(sq_rel_epoch).mean(), np.array(rmse_epoch).mean(), np.array(rmse_log_epoch).mean(), np.array(a1_epoch).mean(), np.array(a2_epoch).mean(), np.array(a3_epoch).mean()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
